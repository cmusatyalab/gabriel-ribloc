#!/usr/bin/env python
#
# Cloudlet Infrastructure for Mobile Computing
#
#   Author: Kiryong Ha <krha@cmu.edu>
#           Zhuo Chen <zhuoc@cs.cmu.edu>
#
#   Copyright (C) 2011-2013 Carnegie Mellon University
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

import multiprocessing
import Queue
from optparse import OptionParser
import os
import pprint
import struct
import sys
import time
import pdb
if os.path.isdir("../../gabriel/server"):
    sys.path.insert(0, "../../gabriel/server")
import gabriel
import gabriel.proxy
import json
import cv2
import numpy as np
import base64
import ikea_cv
sys.path.insert(0, "..")
import zhuocv as zc
import config
import task
import time
from soundpub import SoundPub

LOG = gabriel.logging.getLogger(__name__)
ANDROID_CLIENT=True
config.setup(is_streaming = True)
display_list = config.DISPLAY_LIST_TASK

def process_command_line(argv):
    VERSION = 'gabriel proxy : %s' % gabriel.Const.VERSION
    DESCRIPTION = "Gabriel cognitive assistance"

    parser = OptionParser(usage='%prog [option]', version=VERSION,
            description=DESCRIPTION)

    parser.add_option(
            '-s', '--address', action='store', dest='address',
            help="(IP address:port number) of directory server")
    parser.add_option(
            '-i', '--state', action='store', dest='init_state',
            default=None,
            help="initial state")
    parser.add_option(
            '-p', action='store_true', dest='pubaudio',
            default=False,
            help="whetehr ribloc should publish instruction audio")
    settings, args = parser.parse_args(argv)
    if len(args) >= 1:
        parser.error("invalid arguement")

    if hasattr(settings, 'address') and settings.address is not None:
        if settings.address.find(":") == -1:
            parser.error("Need address and port. Ex) 10.0.0.1:8081")
    return settings, args


class RibLocApp(gabriel.proxy.CognitiveProcessThread):

    def __init__(self, image_queue, output_queue, engine_id, init_state=None, pubaudio=False):
        super(self.__class__, self).__init__(image_queue, output_queue, engine_id)
        self.is_first_image = True
        self.first_n_cnt=0
        self.last_msg=""
        self.dup_msg_cnt=0
        # task initialization
        self.task = task.Task(init_state=init_state)
        if pubaudio:
            self.sp=SoundPub()
        else:
            self.sp=None

    def add_to_byte_array(self, byte_array, extra_bytes):
        return struct.pack("!{}s{}s".format(len(byte_array),len(extra_bytes)), byte_array, extra_bytes)

    def add_output_item(self, header, data, itm_header_key, itm_data):
        header[itm_header_key] = (len(data), len(itm_data))
        return self.add_to_byte_array(data, itm_data)

    def gen_output(self, header, img, speech):
        rtn_data=""
        if img is not None:
            _, buf = cv2.imencode(".jpg", img)
            rtn_data=self.add_output_item(header,
                                 rtn_data,
                                 gabriel.Protocol_result.JSON_KEY_IMAGE,
                                 buf.tobytes())
        if speech is not None:
            rtn_data=self.add_output_item(header,
                                 rtn_data,
                                 gabriel.Protocol_result.JSON_KEY_SPEECH,
                                speech)
        return rtn_data

    @staticmethod
    def rotate_90(img):
        rows,cols,_ = img.shape
        M = cv2.getRotationMatrix2D((cols/2,rows/2),-90,1)
        dst = cv2.warpAffine(img,M,(cols,rows))        
        return dst

    def handle(self, header, data):
        # PERFORM Cognitive Assistance Processing
        LOG.info("processing: ")
        LOG.info("%s\n" % header)

        if self.first_n_cnt < 10:
            header['status'] = 'success'
            rtn_data=self.gen_output(header,None, None)
            self.first_n_cnt+=1
            return rtn_data

        ## preprocessing of input image
        img = zc.raw2cv_image(data)
        if config.ROTATE_IMAGE:
            img=self.rotate_90(img)
        if config.RESIZE_IMAGE:
            img = cv2.resize(img, (720, 480)) 

        _ , objects =ikea_cv.detect_object(img)
        LOG.info("object detection result: %s" % objects)

        ## get instruction based on state
        vis_objects, instruction = self.task.get_instruction(objects, header)
        print 'cur state: {}'.format(self.task.current_state)
        header['status'] = 'success'

        if instruction['speech'] is not None:
            if instruction['speech'] == self.last_msg:
                print 'duplicate speech'
                self.dup_msg_cnt+=1
                if self.dup_msg_cnt < 100:
                    return self.gen_output(header, None, None)
                else:
                    self.dup_msg_cnt=0
            self.last_msg = instruction['speech']

        rtn_data=self.gen_output(header,instruction['image'], instruction['speech'])

        # debug, display
#        zc.check_and_display('input', img, display_list, resize_max = config.DISPLAY_MAX_PIXEL, wait_time = config.DISPLAY_WAIT_TIME)
        if len(vis_objects) > 0:
            print 'visualizing: {}'.format(vis_objects)
        if config.VISUALIZE_ALL:
            vis_objects=objects
        img_object = zc.vis_detections(img, vis_objects, config.LABELS)
        zc.check_and_display("object", img_object,
                             display_list,
                             resize_max = config.DISPLAY_MAX_PIXEL,
                             wait_time = config.DISPLAY_WAIT_TIME)
        if instruction['image'] is not None:
            zc.check_and_display("instruction", instruction['image'],
                                 display_list,
                                 resize_max = config.DISPLAY_MAX_PIXEL,
                                 wait_time = config.DISPLAY_WAIT_TIME)
        if instruction['speech'] is not None and self.sp is not None:
            self.sp.pub(instruction['speech'])
        return rtn_data

if __name__ == "__main__":
    result_queue = multiprocessing.Queue()
    print result_queue._reader

    settings, args = process_command_line(sys.argv[1:])
    ip_addr, port = gabriel.network.get_registry_server_address(settings.address)
    service_list = gabriel.network.get_service_list(ip_addr, port)
    LOG.info("Gabriel Server :")
    LOG.info(pprint.pformat(service_list))

    video_ip = service_list.get(gabriel.ServiceMeta.VIDEO_TCP_STREAMING_IP)
    video_port = service_list.get(gabriel.ServiceMeta.VIDEO_TCP_STREAMING_PORT)
    ucomm_ip = service_list.get(gabriel.ServiceMeta.UCOMM_SERVER_IP)
    ucomm_port = service_list.get(gabriel.ServiceMeta.UCOMM_SERVER_PORT)

    # image receiving and processing threads
    image_queue = Queue.Queue(gabriel.Const.APP_LEVEL_TOKEN_SIZE)
    print "TOKEN SIZE OF OFFLOADING ENGINE: %d" % gabriel.Const.APP_LEVEL_TOKEN_SIZE # TODO
    video_receive_client = gabriel.proxy.SensorReceiveClient((video_ip, video_port), image_queue)
    video_receive_client.start()
    video_receive_client.isDaemon = True
    ribloc_app = RibLocApp(image_queue, result_queue, engine_id ='ribLoc', init_state=settings.init_state, pubaudio=settings.pubaudio)
    ribloc_app.start()
    ribloc_app.isDaemon = True

    # result publish
    result_pub = gabriel.proxy.ResultPublishClient((ucomm_ip, ucomm_port), result_queue)
    result_pub.start()
    result_pub.isDaemon = True

    try:
        while True:
            time.sleep(1)
    except Exception as e:
        pass
    except KeyboardInterrupt as e:
        sys.stdout.write("user exits\n")
    finally:
        if video_receive_client is not None:
            video_receive_client.terminate()
        if ribloc_app is not None:
            ribloc_app.terminate()
        #if acc_client is not None:
        #    acc_client.terminate()
        #if acc_app is not None:
        #    acc_app.terminate()
        result_pub.terminate()

